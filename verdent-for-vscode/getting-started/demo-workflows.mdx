---
title: "Demo: Common Development Workflows"
description: Example of a workflows guide following the 900-1000 line template with scenario-based cookbook structure
---

---

# Common Development Workflows

This demo page showcases the **Workflows Guide** template pattern. This template is designed as a comprehensive cookbook covering 6-8 complete workflows, each following the scenario → steps → tips structure.

<Note>
This is a **demo page** showing template structure, not actual Verdent documentation. Notice the high information density, scenario-based approach, and horizontal rule separators characteristic of workflow cookbooks.
</Note>

### Introduction

This guide provides practical, task-oriented workflows for common development scenarios. Each workflow is complete and standalone, showing you exactly what commands to run and when.

**How to use this guide:**
- Select the workflow tab that matches your task
- Follow the steps in order
- Refer to tips for best practices and common gotchas
- Adapt the examples to your specific project needs

---

<Tabs>
  <Tab title="Starting a New Project">
    **Scenario**: Suppose you need to create a new project from scratch with a modern development setup.

    #### Steps

    1. **Create project directory and initialize version control**:

    ```bash
    # Create and navigate to project directory
    mkdir my-new-project
    cd my-new-project

    # Initialize git repository
    git init

    # Create initial .gitignore
    cat > .gitignore << 'EOF'
    node_modules/
    dist/
    build/
    .env
    .env.local
    *.log
    .DS_Store
    EOF
    ```

    2. **Initialize package manager**:

    ```bash
    # Initialize with npm (creates package.json)
    npm init -y

    # Or use pnpm for faster installs
    pnpm init

    # Or use yarn
    yarn init -y
    ```

    3. **Set up project structure**:

    ```bash
    # Create standard directories
    mkdir -p src/{components,utils,types}
    mkdir -p tests/{unit,integration}
    mkdir -p docs

    # Create entry point
    touch src/index.ts

    # Create README
    cat > README.md << 'EOF'
    # My New Project

    ## Getting Started

    \`\`\`bash
    npm install
    npm run dev
    \`\`\`

    ## Available Scripts

    - `npm run dev` - Start development server
    - `npm run build` - Build for production
    - `npm test` - Run tests
    EOF
    ```

    4. **Install essential dependencies**:

    ```bash
    # Install TypeScript and type definitions
    npm install --save-dev typescript @types/node

    # Initialize TypeScript configuration
    npx tsc --init

    # Install build tools
    npm install --save-dev vite

    # Install linting tools
    npm install --save-dev eslint @typescript-eslint/parser @typescript-eslint/eslint-plugin
    npm install --save-dev prettier eslint-config-prettier
    ```

    5. **Configure package.json scripts**:

    ```json
    {
      "scripts": {
    "dev": "vite",
    "build": "tsc && vite build",
    "preview": "vite preview",
    "test": "vitest",
    "lint": "eslint src --ext .ts,.tsx",
    "format": "prettier --write \"src/**/*.{ts,tsx,json,md}\""
      }
    }
    ```

    6. **Create initial commit**:

    ```bash
    # Stage all files
    git add .

    # Create initial commit
    git commit -m "Initial project setup

    - Initialize npm package
    - Configure TypeScript
    - Set up build tools and linting
    - Create project structure"
    ```

    #### Tips

    <Tip>
    **Project Template Tip**: Save time by creating your own project template or using tools like `create-vite`, `create-next-app`, or `create-react-app` for common setups.
    </Tip>

    - Use `--save-exact` flag when installing critical dependencies to avoid version drift
    - Set up pre-commit hooks early with `husky` to enforce linting before commits
    - Document your setup decisions in README.md for future team members
    - Consider using a mono repo tool like `turborepo` or `nx` for multiple related projects

  </Tab>

  <Tab title="Adding a New Feature">
    **Scenario**: Suppose you need to add a new feature to an existing codebase following best practices for branching and testing.

    #### Steps

    1. **Create a feature branch**:

    ```bash
    # Ensure you're on latest main/master
    git checkout main
    git pull origin main

    # Create and switch to feature branch
    git checkout -b feature/user-authentication

    # Or use switch (Git 2.23+)
    git switch -c feature/user-authentication
    ```

    2. **Plan the feature implementation**:

    ```bash
    # Create a feature plan document
    cat > docs/features/user-authentication.md << 'EOF'
    # User Authentication Feature

    ## Overview
    Implement JWT-based authentication with login/logout functionality.

    ## Components
    - LoginForm component
    - AuthContext for state management
    - API service for auth endpoints
    - Protected route wrapper

    ## API Endpoints
    - POST /api/auth/login
    - POST /api/auth/logout
    - GET /api/auth/verify
    EOF
    ```

    3. **Implement the feature with incremental commits**:

    ```typescript
    // src/services/auth.ts
    export interface LoginCredentials {
      email: string;
      password: string;
    }

    export interface AuthResponse {
      token: string;
      user: {
    id: string;
    email: string;
    name: string;
      };
    }

    export class AuthService {
      private static readonly API_URL = process.env.API_URL || 'http://localhost:3000';

      static async login(credentials: LoginCredentials): Promise<AuthResponse> {
    const response = await fetch(`${this.API_URL}/api/auth/login`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(credentials),
    });

    if (!response.ok) {
      throw new Error('Login failed');
    }

    return response.json();
      }

      static async logout(): Promise<void> {
    const token = localStorage.getItem('authToken');

    await fetch(`${this.API_URL}/api/auth/logout`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${token}`,
      },
    });

    localStorage.removeItem('authToken');
      }

      static async verifyToken(token: string): Promise<boolean> {
    try {
      const response = await fetch(`${this.API_URL}/api/auth/verify`, {
        headers: {
          'Authorization': `Bearer ${token}`,
        },
      });

      return response.ok;
    } catch {
      return false;
    }
      }
    }
    ```

    4. **Write tests for the feature**:

    ```typescript
    // tests/unit/auth.test.ts
    import { describe, it, expect, vi, beforeEach } from 'vitest';
    import { AuthService } from '../../src/services/auth';

    describe('AuthService', () => {
      beforeEach(() => {
    // Clear localStorage before each test
    localStorage.clear();
    // Reset fetch mocks
    vi.restoreAllMocks();
      });

      describe('login', () => {
    it('should successfully login with valid credentials', async () => {
      const mockResponse = {
        token: 'test-token-123',
        user: {
          id: '1',
          email: 'test@example.com',
          name: 'Test User',
        },
      };

      global.fetch = vi.fn().mockResolvedValue({
        ok: true,
        json: async () => mockResponse,
      });

      const result = await AuthService.login({
        email: 'test@example.com',
        password: 'password123',
      });

      expect(result).toEqual(mockResponse);
      expect(fetch).toHaveBeenCalledWith(
        expect.stringContaining('/api/auth/login'),
        expect.objectContaining({
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
        })
      );
    });

    it('should throw error on failed login', async () => {
      global.fetch = vi.fn().mockResolvedValue({
        ok: false,
      });

      await expect(
        AuthService.login({
          email: 'wrong@example.com',
          password: 'wrongpass',
        })
      ).rejects.toThrow('Login failed');
    });
      });

      describe('verifyToken', () => {
    it('should return true for valid token', async () => {
      global.fetch = vi.fn().mockResolvedValue({ ok: true });

      const result = await AuthService.verifyToken('valid-token');

      expect(result).toBe(true);
    });

    it('should return false for invalid token', async () => {
      global.fetch = vi.fn().mockResolvedValue({ ok: false });

      const result = await AuthService.verifyToken('invalid-token');

      expect(result).toBe(false);
    });
      });
    });
    ```

    5. **Commit incrementally as you build**:

    ```bash
    # Commit the service implementation
    git add src/services/auth.ts
    git commit -m "feat: add authentication service

    - Implement login/logout methods
    - Add token verification
    - Include proper error handling"

    # Commit the tests
    git add tests/unit/auth.test.ts
    git commit -m "test: add authentication service tests

    - Test successful login flow
    - Test login failure cases
    - Test token verification"

    # Run tests to ensure they pass
    npm test
    ```

    6. **Create pull request**:

    ```bash
    # Push feature branch to remote
    git push -u origin feature/user-authentication

    # Create PR using GitHub CLI (optional)
    gh pr create --title "Add user authentication" --body "Implements JWT-based auth with login/logout"
    ```

    #### Tips

    <Tip>
    **Feature Branch Naming**: Use prefixes like `feature/`, `bugfix/`, or `hotfix/` to categorize branches. This helps with automation and makes PR lists more scannable.
    </Tip>

    - Keep commits atomic and focused on single changes
    - Write commit messages in imperative mood ("Add feature" not "Added feature")
    - Run tests locally before pushing to avoid CI failures
    - Request review from team members familiar with the affected code areas
    - Update documentation concurrently with code changes

  </Tab>

  <Tab title="Debugging Production Issues">
    **Scenario**: Suppose you need to investigate and fix a bug reported in production that you cannot reproduce locally.

    #### Steps

    1. **Gather information about the issue**:

    ```bash
    # Create an issue investigation document
    cat > docs/incidents/$(date +%Y%m%d)-user-login-failure.md << 'EOF'
    # Incident: User Login Failures

    ## Reported
    - Date: 2024-01-15
    - Reporter: Customer Support
    - Affected users: ~5% of login attempts

    ## Symptoms
    - Login form submits but returns "Network Error"
    - Occurs intermittently
    - More frequent during peak hours (9-11 AM EST)

    ## Environment
    - Production (app.example.com)
    - Browser: Multiple (Chrome, Firefox, Safari)
    - Platform: Web only (mobile app works)

    ## Initial Hypothesis
    - Rate limiting kicking in too aggressively?
    - Database connection pool exhaustion?
    - CDN/proxy timeout issues?
    EOF
    ```

    2. **Access production logs safely**:

    ```bash
    # Fetch logs from production (read-only access)
    # Using kubectl for Kubernetes deployments
    kubectl logs -n production deployment/web-app --tail=1000 > prod-logs.txt

    # Or using cloud provider CLI
    # AWS CloudWatch
    aws logs tail /aws/lambda/auth-function --since 1h --format short > auth-logs.txt

    # Search for error patterns
    grep -i "error\|exception\|failed" prod-logs.txt | head -20
    ```

    3. **Set up enhanced logging temporarily**:

    ```typescript
    // Add temporary debug logging (will be removed after investigation)
    // src/services/auth.ts

    export class AuthService {
      static async login(credentials: LoginCredentials): Promise<AuthResponse> {
    const startTime = performance.now();

    console.debug('[AUTH-DEBUG] Login attempt started', {
      email: credentials.email,
      timestamp: new Date().toISOString(),
    });

    try {
      const response = await fetch(`${this.API_URL}/api/auth/login`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'X-Request-ID': crypto.randomUUID(), // Track specific requests
        },
        body: JSON.stringify(credentials),
      });

      const duration = performance.now() - startTime;

      console.debug('[AUTH-DEBUG] Response received', {
        status: response.status,
        duration: `${duration.toFixed(2)}ms`,
        ok: response.ok,
      });

      if (!response.ok) {
        console.error('[AUTH-DEBUG] Login failed', {
          status: response.status,
          statusText: response.statusText,
        });
        throw new Error('Login failed');
      }

      return response.json();
    } catch (error) {
      console.error('[AUTH-DEBUG] Exception during login', {
        error: error instanceof Error ? error.message : String(error),
        duration: `${(performance.now() - startTime).toFixed(2)}ms`,
      });
      throw error;
    }
      }
    }
    ```

    4. **Deploy debug version to staging or canary**:

    ```bash
    # Create hotfix branch
    git checkout -b hotfix/debug-login-issues

    # Commit debug logging
    git add src/services/auth.ts
    git commit -m "debug: add detailed logging for login investigation

    This commit adds temporary debug logging to investigate
    intermittent login failures. Will be removed once issue is resolved.

    Related incident: docs/incidents/20240115-user-login-failure.md"

    # Deploy to staging first
    npm run build
    npm run deploy:staging

    # If safe, deploy to small percentage of production traffic (canary)
    npm run deploy:canary --percentage=10
    ```

    5. **Monitor and analyze new logs**:

    ```bash
    # Watch logs in real-time
    kubectl logs -n production deployment/web-app -f | grep "AUTH-DEBUG"

    # Collect logs for analysis
    kubectl logs -n production deployment/web-app --since=1h | \
      grep "AUTH-DEBUG" > debug-analysis.log

    # Parse and aggregate data
    cat debug-analysis.log | \
      grep "duration" | \
      awk -F'duration: ' '{print $2}' | \
      awk -F'ms' '{sum+=$1; count++} END {print "Avg:", sum/count "ms", "Count:", count}'
    ```

    6. **Identify and fix the root cause**:

    ```typescript
    // Root cause discovered: Timeout was too aggressive
    // Fix: Increase timeout and add retry logic

    export class AuthService {
      private static readonly TIMEOUT_MS = 10000; // Increased from 5000
      private static readonly MAX_RETRIES = 2;

      static async login(
    credentials: LoginCredentials,
    retryCount = 0
      ): Promise<AuthResponse> {
    try {
      const controller = new AbortController();
      const timeout = setTimeout(() => controller.abort(), this.TIMEOUT_MS);

      const response = await fetch(`${this.API_URL}/api/auth/login`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(credentials),
        signal: controller.signal,
      });

      clearTimeout(timeout);

      if (!response.ok) {
        throw new Error(`Login failed: ${response.statusText}`);
      }

      return response.json();
    } catch (error) {
      // Retry on network errors, but not on auth failures
      if (
        error instanceof Error &&
        error.name === 'AbortError' &&
        retryCount < this.MAX_RETRIES
      ) {
        console.warn(`Login timeout, retrying (${retryCount + 1}/${this.MAX_RETRIES})`);
        await new Promise(resolve => setTimeout(resolve, 1000 * (retryCount + 1)));
        return this.login(credentials, retryCount + 1);
      }

      throw error;
    }
      }
    }
    ```

    7. **Remove debug logging and deploy fix**:

    ```bash
    # Create proper fix commit
    git add src/services/auth.ts
    git commit -m "fix: increase login timeout and add retry logic

    - Increased timeout from 5s to 10s
    - Added exponential backoff retry (max 2 retries)
    - Only retry on timeout, not auth failures

    Fixes intermittent login failures during peak hours.
    Root cause: aggressive timeout causing failures on slow connections.

    Closes #1234"

    # Push and create PR
    git push -u origin hotfix/debug-login-issues
    gh pr create --title "Fix intermittent login timeouts" --label "bugfix,high-priority"
    ```

    #### Tips

    <Tip>
    **Production Debugging**: Always use feature flags or canary deployments when adding debug logging to production. This allows you to enable verbose logging for a subset of users without affecting everyone.
    </Tip>

    - Never deploy debug code directly to production without testing in staging
    - Use structured logging (JSON format) for easier parsing and analysis
    - Set up alerts for error rate increases to catch issues early
    - Document your investigation process for future reference
    - Remove debug logging once the issue is resolved to avoid log bloat

  </Tab>

  <Tab title="Deploying Changes">
    **Scenario**: Suppose you need to deploy your tested and reviewed changes to production following a safe deployment process.

    #### Steps

    1. **Pre-deployment checklist**:

    ```bash
    # Create deployment checklist
    cat > deployment-checklist.md << 'EOF'
    # Deployment Checklist

    ## Pre-Deployment
    - [ ] All tests passing (unit, integration, e2e)
    - [ ] Code review approved by 2+ reviewers
    - [ ] No known critical bugs in staging
    - [ ] Database migrations prepared (if any)
    - [ ] Rollback plan documented
    - [ ] Stakeholders notified of deployment window

    ## During Deployment
    - [ ] Monitor error rates
    - [ ] Watch key metrics (response time, CPU, memory)
    - [ ] Check health endpoints
    - [ ] Verify critical user flows

    ## Post-Deployment
    - [ ] Smoke tests passed
    - [ ] Error rates stable
    - [ ] Performance metrics acceptable
    - [ ] No critical alerts triggered
    - [ ] Update deployment log
    EOF
    ```

    2. **Run comprehensive tests**:

    ```bash
    # Run all test suites
    npm run test:unit
    npm run test:integration
    npm run test:e2e

    # Run linting and type checking
    npm run lint
    npm run type-check

    # Build for production
    npm run build

    # Verify build artifacts
    ls -lh dist/
    ```

    3. **Tag the release**:

    ```bash
    # Fetch latest tags
    git fetch --tags

    # Create new version tag
    npm version patch -m "chore: bump version to %s

    Includes:
    - User authentication feature
    - Login timeout fix
    - Performance improvements"

    # Push tag to remote
    git push --follow-tags
    ```

    4. **Deploy to staging first**:

    ```bash
    # Deploy to staging environment
    npm run deploy:staging

    # Wait for deployment to complete
    echo "Waiting for staging deployment..."
    sleep 30

    # Run smoke tests against staging
    npm run test:smoke -- --env=staging

    # Manual verification
    echo "Verify critical flows at https://staging.example.com"
    echo "1. User login"
    echo "2. Data loading"
    echo "3. Form submissions"
    read -p "Press enter when staging verification complete..."
    ```

    5. **Deploy to production with monitoring**:

    ```bash
    # Start monitoring in separate terminal
    # Terminal 1: Watch error logs
    kubectl logs -n production deployment/web-app -f | grep "ERROR"

    # Terminal 2: Watch metrics
    watch -n 5 'kubectl top pods -n production'

    # Main terminal: Execute deployment
    npm run deploy:production

    # Deployment script includes:
    # - Blue-green deployment (zero downtime)
    # - Gradual traffic shift (10% → 50% → 100%)
    # - Automatic health checks
    # - Rollback trigger on errors
    ```

    6. **Post-deployment verification**:

    ```bash
    # Run automated smoke tests
    npm run test:smoke -- --env=production

    # Check health endpoints
    curl https://api.example.com/health
    # Expected: {"status":"healthy","version":"1.2.3"}

    # Verify critical endpoints
    curl -H "Authorization: Bearer $TEST_TOKEN" \
      https://api.example.com/api/user/profile
    # Expected: 200 OK with user data

    # Check error rates in monitoring dashboard
    echo "Check Datadog/NewRelic dashboard for:"
    echo "- Error rate < 0.1%"
    echo "- p95 latency < 500ms"
    echo "- No 5xx errors"
    ```

    7. **Update deployment log and notify stakeholders**:

    ```bash
    # Log the deployment
    cat >> DEPLOYMENTS.md << EOF

    ## Deployment $(date +%Y-%m-%d)

    **Version**: v1.2.3
    **Deployed by**: $(git config user.name)
    **Time**: $(date +%H:%M:%S)

    ### Changes
    - Added user authentication feature
    - Fixed intermittent login timeouts
    - Improved login performance

    ### Metrics
    - Deployment duration: 15 minutes
    - Zero downtime: ✓
    - Rollback required: No
    - Post-deploy error rate: 0.02%

    ### Issues
    None

    EOF

    # Notify team via Slack/Discord/Email
    curl -X POST $SLACK_WEBHOOK_URL \
      -H 'Content-Type: application/json' \
      -d '{
    "text": ":rocket: Production deployment complete: v1.2.3\n• User authentication\n• Login timeout fixes\n• No issues detected"
      }'
    ```

    #### Tips

    <Tip>
    **Deployment Windows**: Schedule deployments during low-traffic periods (e.g., Tuesday-Thursday mornings) to minimize user impact if issues arise. Avoid Friday deployments when possible.
    </Tip>

    - Use feature flags to decouple deployment from feature release
    - Always have a documented rollback procedure ready
    - Monitor for at least 30 minutes after deployment before considering it successful
    - Keep deployments small and frequent rather than large and rare
    - Automate deployment checklists to reduce human error

  </Tab>

  <Tab title="Refactoring Legacy Code">
    **Scenario**: Suppose you need to refactor a complex legacy module to improve maintainability without breaking existing functionality.

    #### Steps

    1. **Understand current behavior through tests**:

    ```bash
    # First, add characterization tests if none exist
    # These tests document current behavior, even if it's not ideal
    ```

    ```typescript
    // tests/legacy/user-manager.characterization.test.ts
    import { describe, it, expect } from 'vitest';
    import { UserManager } from '../../src/legacy/user-manager';

    describe('UserManager - Current Behavior (Characterization Tests)', () => {
      // These tests document how the system CURRENTLY works
      // Not necessarily how it SHOULD work

      it('should handle undefined input by returning empty string', () => {
    const manager = new UserManager();
    // Current behavior: returns empty string instead of throwing
    expect(manager.formatUserName(undefined as any)).toBe('');
      });

      it('should concatenate user parts with space', () => {
    const manager = new UserManager();
    const user = { firstName: 'John', lastName: 'Doe', title: 'Dr' };
    // Current behavior includes title
    expect(manager.formatUserName(user)).toBe('Dr John Doe');
      });

      // Document all edge cases you find
      it('should handle missing lastName gracefully', () => {
    const manager = new UserManager();
    const user = { firstName: 'John', lastName: null };
    expect(manager.formatUserName(user)).toBe('John');
      });
    });
    ```

    2. **Create a refactoring plan**:

    ```markdown
    # Refactoring Plan: UserManager Module

    ## Current Issues
    1. 500+ lines in single file
    2. No clear separation of concerns
    3. Mixed responsibilities (formatting, validation, persistence)
    4. Hard to test due to tight coupling
    5. Inconsistent error handling

    ## Refactoring Goals
    1. Split into focused modules (< 200 lines each)
    2. Extract formatting logic to separate utility
    3. Separate data access from business logic
    4. Add proper TypeScript types
    5. Improve error handling

    ## Approach
    - Create new modules alongside old code
    - Migrate one function at a time
    - Keep old tests passing throughout
    - Add new tests for refactored code
    - Remove old code only when fully migrated

    ## Risk Mitigation
    - Feature flag to switch between old/new implementation
    - Parallel run tests (compare old vs new outputs)
    - Staged rollout (10% → 50% → 100%)
    ```

    3. **Extract smaller, focused modules**:

    ```typescript
    // src/utils/user-formatter.ts (NEW)
    export interface UserName {
      firstName: string;
      lastName?: string | null;
      title?: string | null;
    }

    export class UserFormatter {
      static formatFullName(user: UserName | null | undefined): string {
    if (!user || !user.firstName) {
      return '';
    }

    const parts: string[] = [];

    if (user.title) {
      parts.push(user.title);
    }

    parts.push(user.firstName);

    if (user.lastName) {
      parts.push(user.lastName);
    }

    return parts.join(' ');
      }

      static formatLastNameFirst(user: UserName | null | undefined): string {
    if (!user || !user.firstName) {
      return '';
    }

    if (!user.lastName) {
      return user.firstName;
    }

    return `${user.lastName}, ${user.firstName}`;
      }
    }
    ```

    4. **Add comprehensive tests for new code**:

    ```typescript
    // tests/unit/user-formatter.test.ts
    import { describe, it, expect } from 'vitest';
    import { UserFormatter } from '../../src/utils/user-formatter';

    describe('UserFormatter', () => {
      describe('formatFullName', () => {
    it('should format complete name with title', () => {
      const user = { firstName: 'John', lastName: 'Doe', title: 'Dr' };
      expect(UserFormatter.formatFullName(user)).toBe('Dr John Doe');
    });

    it('should format name without title', () => {
      const user = { firstName: 'John', lastName: 'Doe' };
      expect(UserFormatter.formatFullName(user)).toBe('John Doe');
    });

    it('should handle missing lastName', () => {
      const user = { firstName: 'John' };
      expect(UserFormatter.formatFullName(user)).toBe('John');
    });

    it('should return empty string for null user', () => {
      expect(UserFormatter.formatFullName(null)).toBe('');
    });

    it('should return empty string for undefined user', () => {
      expect(UserFormatter.formatFullName(undefined)).toBe('');
    });

    it('should handle empty firstName', () => {
      const user = { firstName: '', lastName: 'Doe' };
      expect(UserFormatter.formatFullName(user)).toBe('');
    });
      });

      describe('formatLastNameFirst', () => {
    it('should format as "Last, First"', () => {
      const user = { firstName: 'John', lastName: 'Doe' };
      expect(UserFormatter.formatLastNameFirst(user)).toBe('Doe, John');
    });

    it('should return firstName only when no lastName', () => {
      const user = { firstName: 'John' };
      expect(UserFormatter.formatLastNameFirst(user)).toBe('John');
    });
      });
    });
    ```

    5. **Gradually migrate to new implementation**:

    ```typescript
    // src/legacy/user-manager.ts (UPDATED)
    import { UserFormatter } from '../utils/user-formatter';

    export class UserManager {
      private useNewImplementation: boolean;

      constructor() {
    // Feature flag to control rollout
    this.useNewImplementation = process.env.USE_NEW_USER_FORMATTER === 'true';
      }

      formatUserName(user: any): string {
    if (this.useNewImplementation) {
      // New implementation
      return UserFormatter.formatFullName(user);
    } else {
      // Old implementation (keeping for now)
      return this.formatUserNameLegacy(user);
    }
      }

      private formatUserNameLegacy(user: any): string {
    // Original implementation preserved
    if (!user) return '';
    let name = '';
    if (user.title) name += user.title + ' ';
    if (user.firstName) name += user.firstName;
    if (user.lastName) name += ' ' + user.lastName;
    return name.trim();
      }
    }
    ```

    6. **Run parallel comparison tests**:

    ```typescript
    // tests/integration/user-manager-migration.test.ts
    import { describe, it, expect } from 'vitest';
    import { UserManager } from '../../src/legacy/user-manager';
    import { UserFormatter } from '../../src/utils/user-formatter';

    describe('UserManager Migration - Parallel Tests', () => {
      const testCases = [
    { firstName: 'John', lastName: 'Doe', title: 'Dr' },
    { firstName: 'Jane', lastName: 'Smith' },
    { firstName: 'Bob' },
    { firstName: 'Alice', lastName: null },
    null,
    undefined,
      ];

      testCases.forEach((testCase, index) => {
    it(`should produce same output for case ${index}`, () => {
      const oldManager = new UserManager();
      process.env.USE_NEW_USER_FORMATTER = 'false';
      const oldResult = oldManager.formatUserName(testCase);

      process.env.USE_NEW_USER_FORMATTER = 'true';
      const newResult = oldManager.formatUserName(testCase);

      expect(newResult).toBe(oldResult);
    });
      });
    });
    ```

    7. **Complete migration and cleanup**:

    ```bash
    # Once parallel tests pass and new implementation is stable in production

    # Remove feature flag code
    git add src/legacy/user-manager.ts
    git commit -m "refactor: remove feature flag for user formatter

    New implementation has been stable in production for 2 weeks.
    All parallel comparison tests passing.
    Ready to remove legacy code."

    # Remove legacy implementation
    git add src/legacy/user-manager.ts
    git commit -m "refactor: remove legacy user formatter implementation

    Completes migration to new UserFormatter utility.
    Old formatUserNameLegacy method no longer needed."

    # Update imports throughout codebase
    git add src/
    git commit -m "refactor: use UserFormatter directly instead of UserManager

    Removed unnecessary wrapper layer now that migration is complete."
    ```

    #### Tips

    <Tip>
    **Refactoring Safety**: Use characterization tests to document current behavior before refactoring. These tests ensure you don't accidentally change behavior during the refactor.
    </Tip>

    - Refactor in small, incremental steps with tests passing at each step
    - Use feature flags to control rollout of refactored code
    - Keep both old and new implementations running in parallel initially
    - Never refactor and add features in the same commit
    - Consider using automated refactoring tools like `ts-morph` or `jscodeshift` for large-scale changes

  </Tab>

  <Tab title="Performance Optimization">
    **Scenario**: Suppose you need to investigate and improve application performance after users report slow load times.

    #### Steps

    1. **Establish performance baseline**:

    ```typescript
    // src/utils/performance.ts
    export class PerformanceMonitor {
      private static marks = new Map<string, number>();

      static startMeasure(label: string): void {
    this.marks.set(label, performance.now());
      }

      static endMeasure(label: string): number {
    const start = this.marks.get(label);
    if (!start) {
      console.warn(`No start mark found for: ${label}`);
      return 0;
    }

    const duration = performance.now() - start;
    this.marks.delete(label);

    console.info(`[PERF] ${label}: ${duration.toFixed(2)}ms`);
    return duration;
      }

      static async measureAsync<T>(
    label: string,
    fn: () => Promise<T>
      ): Promise<T> {
    this.startMeasure(label);
    try {
      return await fn();
    } finally {
      this.endMeasure(label);
    }
      }
    }
    ```

    2. **Instrument critical paths**:

    ```typescript
    // src/pages/Dashboard.tsx
    import { PerformanceMonitor } from '../utils/performance';

    export function Dashboard() {
      useEffect(() => {
    PerformanceMonitor.startMeasure('dashboard-mount');

    // Load data
    const loadData = async () => {
      await PerformanceMonitor.measureAsync('fetch-user-data', async () => {
        const userData = await fetchUserData();
        setUser(userData);
      });

      await PerformanceMonitor.measureAsync('fetch-dashboard-stats', async () => {
        const stats = await fetchDashboardStats();
        setStats(stats);
      });

      await PerformanceMonitor.measureAsync('fetch-recent-activity', async () => {
        const activity = await fetchRecentActivity();
        setActivity(activity);
      });

      PerformanceMonitor.endMeasure('dashboard-mount');
    };

    loadData();
      }, []);

      return (/* Dashboard UI */);
    }
    ```

    3. **Collect and analyze performance data**:

    ```bash
    # Analyze performance logs from production
    # Extract timing data
    grep "PERF" production.log | \
      awk -F': ' '{print $2}' | \
      awk '{sum+=$1; count++; if($1>max) max=$1; if(min=="" || $1<min) min=$1} \
       END {print "Avg:", sum/count "ms", "Min:", min "ms", "Max:", max "ms"}'

    # Output:
    # dashboard-mount: Avg: 2847ms  Min: 1203ms  Max: 8945ms
    # fetch-user-data: Avg: 342ms   Min: 145ms   Max: 1203ms
    # fetch-dashboard-stats: Avg: 1891ms  Min: 823ms  Max: 6432ms
    # fetch-recent-activity: Avg: 614ms   Min: 235ms   Max: 1310ms
    ```

    4. **Identify bottlenecks and optimize**:

    ```typescript
    // BEFORE: Sequential loading (slow)
    const loadData = async () => {
      const userData = await fetchUserData();        // 342ms
      const stats = await fetchDashboardStats();     // 1891ms
      const activity = await fetchRecentActivity();  // 614ms
      // Total: ~2847ms
    };

    // AFTER: Parallel loading (fast)
    const loadData = async () => {
      const [userData, stats, activity] = await Promise.all([
    fetchUserData(),        // 342ms
    fetchDashboardStats(),  // 1891ms (runs in parallel)
    fetchRecentActivity(),  // 614ms  (runs in parallel)
      ]);
      // Total: ~1891ms (longest single request)
      // Improvement: 33% faster
    };
    ```

    5. **Implement caching strategy**:

    ```typescript
    // src/utils/cache.ts
    export class Cache {
      private static store = new Map<string, { data: any; timestamp: number }>();
      private static readonly TTL = 5 * 60 * 1000; // 5 minutes

      static get<T>(key: string): T | null {
    const cached = this.store.get(key);
    if (!cached) return null;

    const age = Date.now() - cached.timestamp;
    if (age > this.TTL) {
      this.store.delete(key);
      return null;
    }

    return cached.data;
      }

      static set(key: string, data: any): void {
    this.store.set(key, {
      data,
      timestamp: Date.now(),
    });
      }

      static clear(): void {
    this.store.clear();
      }
    }

    // Use cache in data fetching
    export async function fetchDashboardStats(): Promise<DashboardStats> {
      const cacheKey = 'dashboard-stats';
      const cached = Cache.get<DashboardStats>(cacheKey);

      if (cached) {
    console.info('[CACHE HIT] dashboard-stats');
    return cached;
      }

      console.info('[CACHE MISS] dashboard-stats');
      const stats = await fetch('/api/dashboard/stats').then(r => r.json());

      Cache.set(cacheKey, stats);
      return stats;
    }
    ```

    6. **Optimize bundle size**:

    ```bash
    # Analyze bundle size
    npx vite-bundle-visualizer

    # Results show:
    # - lodash: 500KB (only using 3 functions!)
    # - moment.js: 232KB (not tree-shakeable)
    # - Total bundle: 1.8MB

    # Optimize imports
    # BEFORE
    import _ from 'lodash';
    _.debounce(fn, 300);

    # AFTER (import only what you need)
    import debounce from 'lodash/debounce';
    debounce(fn, 300);

    # Replace heavy dependencies
    # BEFORE
    import moment from 'moment';
    const formatted = moment(date).format('YYYY-MM-DD');

    # AFTER (use date-fns instead)
    import { format } from 'date-fns';
    const formatted = format(date, 'yyyy-MM-dd');

    # Results after optimization:
    # - Bundle reduced from 1.8MB to 600KB (67% reduction)
    # - Initial load time: 3.2s → 1.1s (66% faster)
    ```

    7. **Measure improvement and document**:

    ```bash
    # Re-run performance measurements
    npm run test:performance

    # Compare before/after metrics
    cat > docs/performance-optimization-results.md << EOF
    # Performance Optimization Results

    ## Before Optimization
    - Dashboard load time: avg 2847ms (p95: 5200ms)
    - Bundle size: 1.8MB
    - Time to Interactive: 3.2s

    ## Changes
    1. Parallelized data fetching (Promise.all)
    2. Added caching layer (5min TTL)
    3. Optimized bundle (tree-shaking, dependency replacement)
    4. Lazy-loaded non-critical components

    ## After Optimization
    - Dashboard load time: avg 945ms (p95: 1450ms)
    - Bundle size: 600KB
    - Time to Interactive: 1.1s

    ## Improvements
    - 67% faster dashboard load
    - 67% smaller bundle
    - 66% faster time to interactive

    ## Trade-offs
    - Cache adds memory overhead (~5MB max)
    - Requires cache invalidation strategy
    - date-fns has different API than moment
    EOF
    ```

    #### Tips

    <Tip>
    **Performance Optimization Priority**: Focus on the metrics that matter to users first (load time, interactivity) before optimizing internal metrics. Use real user monitoring (RUM) data to guide decisions.
    </Tip>

    - Measure before optimizing - don't guess where the bottlenecks are
    - Use production-like data volumes when testing performance
    - Consider using web workers for heavy computations
    - Implement progressive loading for large datasets
    - Monitor performance continuously, not just during optimization sprints
  </Tab>
</Tabs>

---

## Conclusion

This guide covered common development workflows:

1. **Starting a New Project** - Setting up a modern development environment
2. **Adding a New Feature** - Feature branches, testing, and pull requests
3. **Debugging Production Issues** - Safe investigation and resolution
4. **Deploying Changes** - Staging, production deployment, and verification
5. **Refactoring Legacy Code** - Safe incremental refactoring
6. **Performance Optimization** - Measuring, optimizing, and validating improvements

Each workflow follows a consistent pattern:
- Clear scenario description
- Step-by-step instructions with code examples
- Tips and best practices
- Real-world considerations

Adapt these workflows to your specific project needs and team practices.
